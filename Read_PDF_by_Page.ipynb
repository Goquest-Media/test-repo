{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMYh890/+mkFKL3Fzd7JU+r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Goquest-Media/test-repo/blob/main/Read_PDF_by_Page.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils\n",
        "!pip install PyPDF2\n",
        "!pip install pdf2image\n",
        "!pip install pytesseract\n",
        "!apt install tesseract-ocr -y\n",
        "!pip install gdown\n",
        "!pip install openai\n"
      ],
      "metadata": {
        "id": "duph35Rn4q7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyac3ype5D5I",
        "outputId": "47f05a79-6824-48ae-f830-16d6a3e0f622"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "import openai\n",
        "import gdown\n",
        "\n",
        "# Set the variables\n",
        "file_path = \"/content/gdrive/MyDrive/temp/pdf_source/your_file.pdf\"\n",
        "file_id = \"1SsvnE9Mre1WR3Htyu1J_c0IrvvW7aTg3\"  # replace with your actual Google Drive file ID\n",
        "output_file = \"output.csv\"\n",
        "api_key = \"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\"  # replace with your actual OpenAI API key\n",
        "\n",
        "\n",
        "# Function to extract text from pdf\n",
        "def extract_text_from_pdf(file_path):\n",
        "    try:\n",
        "        pdf_file = open(file_path, 'rb')\n",
        "        reader = PyPDF2.PdfReader(pdf_file)\n",
        "        text = \"\"\n",
        "        links = []\n",
        "        # Extract text from each page\n",
        "        for page_num in range(min(len(reader.pages), 9)):\n",
        "            page = reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "            #print (text)\n",
        "\n",
        "            if '/Annots' in page:\n",
        "                  annotations = page['/Annots']\n",
        "                  for annotation_ref in annotations:\n",
        "                      annotation = reader.get_object(annotation_ref)\n",
        "                      if annotation and isinstance(annotation, PyPDF2.generic.DictionaryObject):\n",
        "                          subtype = annotation.get('/Subtype')\n",
        "                          if subtype == '/Link':\n",
        "                              link_dict = annotation.get('/A')\n",
        "                              if link_dict and isinstance(link_dict, PyPDF2.generic.DictionaryObject):\n",
        "                                  link = link_dict.get('/URI')\n",
        "                                  if link:\n",
        "                                      link_text = f\"<{link}>\"\n",
        "                                      links.append((link_text, page_num))\n",
        "                                      rect = annotation.get('/Rect')\n",
        "                                      rect = [int(value) for value in rect]  # Convert indices to integers\n",
        "                                      text = text[:rect[1] // 8] + link_text + text[rect[3] // 8:]\n",
        "        pdf_file.close()\n",
        "        #print (text)\n",
        "\n",
        "\n",
        "        # If no text was extracted, try OCR.\n",
        "        if text.strip() == \"\":\n",
        "            images = convert_from_path(file_path)\n",
        "            # Extract text from each image (page)\n",
        "            for i in range(len(images)):\n",
        "                text += pytesseract.image_to_string(images[i])\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error during PDF text extraction: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to write to CSV\n",
        "def write_to_csv(data, output_file):\n",
        "    try:\n",
        "        with open(output_file, 'w', newline='') as file:\n",
        "            file.write(data)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during CSV file writing: {e}\")\n",
        "\n",
        "# Helper function to generate prompt text and perform OpenAI completion\n",
        "def generate_completion(file_path, file_id, api_key):\n",
        "    try:\n",
        "        gdown.download(f\"https://drive.google.com/uc?id={file_id}\", file_path, quiet=False)\n",
        "        pdf_text = extract_text_from_pdf(file_path)\n",
        "        prompt_command = '''\n",
        "                        Replace the character | from the text below with a comma.\n",
        "                    Extract structured data for shows in csv from the below text.\n",
        "                    Combine similar entities in one cell separated by comma\n",
        "                    Add | as a delimiter\n",
        "                    Extract the following entities\n",
        "                    Title Name\n",
        "                    Language\n",
        "                    Genre\n",
        "                    Country\n",
        "                    Year or Release Year\n",
        "                    number of Episodes\n",
        "                    Runtime or time length, Name the columns as RUNTIME\n",
        "                    Synopsis of the show or movie. Name the column SYNOPSIS\n",
        "                    Trailer or screener url\n",
        "                    other Links and URLs on each page. Name the columns OTHER LINKS\n",
        "                    create a link to search on imdb using the title name, country and language. Name the column as IMDB SEARCH\n",
        "                    create a link to search on google using using the title name, country and language GOOGLE SEARCH\n",
        "                    createa link to search on youtube using the title name, country and language YOUTUBE SEARCH\n",
        "                    email ids of the sales person or sales email ids as Sales Emails\n",
        "                    Name of the company if mentioned in the text as Company Name\n",
        "        '''\n",
        "        prompt_text = prompt_command + pdf_text\n",
        "        #print(prompt_text)\n",
        "\n",
        "        if pdf_text is not None:\n",
        "            openai.api_key = api_key\n",
        "            response = openai.Completion.create(\n",
        "                model=\"text-davinci-003\",\n",
        "                prompt=prompt_text,\n",
        "                temperature=0,\n",
        "                max_tokens=1000,\n",
        "                top_p=1.0,\n",
        "                frequency_penalty=0.0,\n",
        "                presence_penalty=0.0\n",
        "            )\n",
        "            print(response.choices[0].text.strip())\n",
        "            return response.choices[0].text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error during PDF file download, text extraction, or text completion with OpenAI: {e}\")\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "8LypMalC43EP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the helper function\n",
        "\n",
        "completion_text = generate_completion(file_path, file_id, api_key)\n",
        "#print (completion_text)\n",
        "if completion_text is not None:\n",
        "    # Write the completion to a CSV\n",
        "    write_to_csv(completion_text, output_file)\n",
        "else:\n",
        "    print(\"Error occurred during OpenAI completion.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hNFT2xNJ5Egt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}